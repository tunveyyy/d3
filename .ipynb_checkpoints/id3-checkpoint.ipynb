{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    node_count = 0\n",
    "    \n",
    "    def __init__(self, attribute_name, is_continuous, threshold, total_positive, total_negative, is_leaf, label, branch):\n",
    "        self.attribute_name = attribute_name\n",
    "        self.is_continuous = is_continuous\n",
    "        self.threshold = threshold\n",
    "        self.total_positive = total_positive\n",
    "        self.total_negative = total_negative\n",
    "        self.is_leaf = is_leaf\n",
    "        self.label = label\n",
    "        self.branch = branch\n",
    "        Node.node_count += 1\n",
    "        \n",
    "    def get_total_nodes(self):\n",
    "        return self.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_temp(path):\n",
    "    column_names = ['days', 'outlook', 'temperature', 'humidity', 'wind', 'decision']\n",
    "    data = pd.read_csv(path, names = column_names)\n",
    "    data = data.drop(['days'], axis = 1)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(train_data_path, dev_data_path, test_data_path):\n",
    "    column_names = ['age', 'workclass', 'education', 'marital-status', 'occupation', 'race', 'sex', 'hours', 'country', 'income']\n",
    "    train_data = pd.read_csv(train_data_path, names = column_names)\n",
    "    dev_data = pd.read_csv(dev_data_path, names = column_names)\n",
    "    test_data = pd.read_csv(test_data_path, names = column_names)\n",
    "    \n",
    "    return (train_data, dev_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_values(data):\n",
    "    \n",
    "    attributes = data.columns.values\n",
    "    index = np.argwhere(attributes == attributes[-1])\n",
    "    attributes = np.delete(attributes, index)\n",
    "    \n",
    "    labels = np.unique(data.iloc[:, -1])\n",
    "    \n",
    "    positive_label = labels[0]\n",
    "    negative_label = labels[1]\n",
    "    \n",
    "    return attributes, positive_label, negative_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "\n",
    "    def __init__(self, positive_label_val, negative_label_val):\n",
    "        self.positive_label_val = positive_label_val\n",
    "        self.negative_label_val = negative_label_val\n",
    "    \n",
    "    def build_tree(self, data, attributes):\n",
    "        \n",
    "        # Create a node\n",
    "        node = Node(None, False, None, None, None, None, False, None)\n",
    "\n",
    "        # Get positive and negative label\n",
    "        values, count = np.unique(data.iloc[:, -1], return_counts = True)\n",
    "        val_count = dict(zip(values, count))\n",
    "        \n",
    "        positive_label = 0\n",
    "        negative_label = 0\n",
    "        \n",
    "        if(len(val_count) == 2):\n",
    "            positive_label = list(val_count)[0]\n",
    "            negative_label = list(val_count)[1]\n",
    "            node.total_positive = val_count[positive_label]\n",
    "            node.total_negative = val_count[negative_label]\n",
    "        else:\n",
    "            if(self.positive_label_val == list(val_count.keys())[0]):\n",
    "                positive_label = list(val_count)[0]\n",
    "                negative_label = 0 \n",
    "                node.total_positive = val_count[positive_label]\n",
    "                node.total_negative = 0\n",
    "            else:\n",
    "                positive_label = 0\n",
    "                negative_label = list(val_count)[0]\n",
    "                node.total_positive = 0\n",
    "                node.total_negative = val_count[negative_label]\n",
    "\n",
    "        \n",
    "            \n",
    "        if(node.total_negative == 0):\n",
    "            node.is_leaf = True\n",
    "            node.label = positive_label\n",
    "            return node\n",
    "\n",
    "        if(node.total_positive == 0):\n",
    "            node.is_leaf = True\n",
    "            node.label = negative_label\n",
    "            return node\n",
    "\n",
    "        if(len(attributes) == 0):\n",
    "            node.is_leaf = True\n",
    "            if(node.total_positive > node.total_negative):\n",
    "                node.label = positive_label\n",
    "            else:\n",
    "                node.label = negative_label\n",
    "            return node\n",
    "\n",
    "        else:\n",
    "\n",
    "            info_gains = {}\n",
    "            thresholds = {}\n",
    "\n",
    "            for attribute in attributes:\n",
    "                if(np.issubdtype(train_data[attribute].dtype.name, np.integer)):\n",
    "                    thresholds[attribute], info_gains[attribute] = self.calculate_threshold(data[attribute], data.iloc[:, -1])\n",
    "                else:\n",
    "                    info_gains[attribute] = self.information_gain(data[attribute], data.iloc[:, -1])\n",
    "\n",
    "            # Attribute with maximum gain\n",
    "            max_gain_attr = max(info_gains.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "            # If continuous attribute, set threshold value\n",
    "            if(max_gain_attr in list(thresholds.keys())):\n",
    "                node.threshold = thresholds[max_gain_attr]\n",
    "                node.is_continuous = True\n",
    "\n",
    "            node.attribute_name = max_gain_attr\n",
    "            node.branch = {}\n",
    "            \n",
    "            # Check if the best attribute is continuous or categorical\n",
    "            if(node.is_continuous):\n",
    "                for value in ['True', 'False']:\n",
    "                    if(value == 'True'):\n",
    "                        data[max_gain_attr] = np.where(data[max_gain_attr] < node.threshold, 'True', 'False')\n",
    "                    node.branch[value] = None\n",
    "                    subset = data[data[max_gain_attr] == value]\n",
    "                    if(subset.shape[0] == 0):\n",
    "                        node.branch[value] = Node(None, True, None, None, None, None, True, None)\n",
    "                        c, v = np.unique(data.iloc[:,-1], return_counts = True)\n",
    "                        c_v = dict(zip(c, v))\n",
    "                        key = max(c_v.items(), key=operator.itemgetter(1))[0]\n",
    "                        node.branch[value].label = key\n",
    "                    else:\n",
    "                        index = np.argwhere(attributes == max_gain_attr)\n",
    "                        attributes = np.delete(attributes, index)\n",
    "                        node.branch[value] = self.build_tree(subset, attributes)\n",
    "                \n",
    "            else:\n",
    "                # For each unique value from attribute column\n",
    "                for value in np.unique(data[max_gain_attr]):\n",
    "                    node.branch[value] = None\n",
    "                    subset = data[data[max_gain_attr] == value]\n",
    "                    if(subset.shape[0] == 0):\n",
    "                        node.branch[value] = Node(None, False, None, None, None, None, True, None)\n",
    "                        c, v = np.unique(data.iloc[:,-1], return_counts = True)\n",
    "                        c_v = dict(zip(c, v))\n",
    "                        key = max(c_v.items(), key=operator.itemgetter(1))[0]\n",
    "                        node.branch[value].label = key\n",
    "                    else:\n",
    "                        index = np.argwhere(attributes == max_gain_attr)\n",
    "                        attributes = np.delete(attributes, index)\n",
    "                        node.branch[value] = self.build_tree(subset, attributes)\n",
    "\n",
    "        return node\n",
    "    \n",
    "    def calculate_threshold(self, data, label):\n",
    "        data = data.values\n",
    "        label = label.values\n",
    "        indexes = data.argsort()\n",
    "        data = np.flip(data[indexes[::-1]])\n",
    "        label = np.flip(label[indexes[::-1]])\n",
    "        label_df = pd.DataFrame(label)\n",
    "        candidate_threshold = []\n",
    "        info_gains = []\n",
    "\n",
    "        for i in range(data.size - 1):\n",
    "            threshold = data[i] + (data[i + 1] - data[i]) / 2\n",
    "            if threshold not in candidate_threshold:\n",
    "                candidate_threshold.append(threshold)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        for threshold in candidate_threshold:\n",
    "            values = data < threshold\n",
    "            values_df = pd.DataFrame(values)\n",
    "            gain = self.information_gain(values_df, label_df)\n",
    "            info_gains.append(gain)\n",
    "\n",
    "        m = max(info_gains)\n",
    "        max_posn = [i for i, j in enumerate(info_gains) if j == m]\n",
    "        candidate_threshold = np.array(candidate_threshold)\n",
    "        threshold = candidate_threshold[max_posn][0]\n",
    "        \n",
    "        return threshold, m\n",
    "    \n",
    "    def information_gain(self, data, label):\n",
    "        attributes, count = np.unique(data, return_counts = True)\n",
    "        attribute_count = dict(zip(attributes, count))\n",
    "        label = label.values\n",
    "        data = data.values\n",
    "        entropies = []\n",
    "        for attribute in attribute_count:\n",
    "            index = np.where(data == attribute)\n",
    "            op_cls = np.take(label, index)[0]\n",
    "            ops, total = np.unique(op_cls, return_counts = True)\n",
    "            ops_total = dict(zip(ops, total))\n",
    "            entropy = 0\n",
    "            try:\n",
    "                entropy = self.calculate_entropy(ops_total[list(ops_total)[0]], ops_total[list(ops_total)[1]])\n",
    "            except:\n",
    "                entropy = self.calculate_entropy(ops_total[list(ops_total)[0]])\n",
    "            entropy = entropy * (attribute_count[attribute] / len(label))\n",
    "            entropies.append(entropy)\n",
    "        ops, total = np.unique(label, return_counts = True)\n",
    "        ops_total = dict(zip(ops, total))\n",
    "        \n",
    "        entropy = self.calculate_entropy(ops_total[list(ops_total)[0]], ops_total[list(ops_total)[1]])\n",
    "        information = entropy - np.sum(entropies)\n",
    "        return information\n",
    "    \n",
    "    def calculate_entropy(self, positive, negative = 0):\n",
    "        total = positive + negative\n",
    "        if negative == 0:\n",
    "            return - (positive/total) * math.log((positive/total), 2)\n",
    "        else:\n",
    "            return - (positive/total) * math.log((positive/total), 2) - (negative/total) * math.log((negative/total), 2)\n",
    "        \n",
    "    \n",
    "    def score(self, data, node):\n",
    "        labels = data.iloc[:, -1].values\n",
    "        data = data.values\n",
    "        \n",
    "        print(labels)\n",
    "        print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_data_path = 'income-data/income.train.txt'\n",
    "    dev_data_path = 'income-data/income.dev.txt'\n",
    "    test_data_path = 'income-data/income.test.txt'\n",
    "    temp_data_path = 'income-data/data.csv'\n",
    "    \n",
    "    (train_data, dev_data, test_data) = read_data(train_data_path, dev_data_path, test_data_path)\n",
    "    \n",
    "    #train_data = read_temp(temp_data_path)\n",
    "    \n",
    "    (attributes, positive_lab, negative_lab) = get_initial_values(train_data)\n",
    "    \n",
    "    # Create an instance of Decision Tree\n",
    "    dt = DecisionTree(positive_lab, negative_lab)\n",
    "    \n",
    "    # Build the tree\n",
    "    root = dt.build_tree(train_data, attributes)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7516\n",
      "0.2393899204244032\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "' Dominican-Republic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5394d48c2d4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdev_acuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-83044caa7c39>\u001b[0m in \u001b[0;36mscore\u001b[1;34m(data, node)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattribute_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbranch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0my_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ' Dominican-Republic'"
     ]
    }
   ],
   "source": [
    "# Get training accuracy\n",
    "train_accuracy = score(train_data, root)\n",
    "dev_acuracy = score(dev_data, root)\n",
    "test_accuracy = score(test_data, root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(data, node):\n",
    "    y_hat = []\n",
    "    y = data.iloc[:, -1].values\n",
    "    x = data.drop(data.columns.values[-1], axis = 1)\n",
    "    \n",
    "    for key, value in x.iterrows():\n",
    "        while(node.is_leaf != True):\n",
    "            # If the column is continuous\n",
    "            if(np.issubdtype(x[node.attribute_name].dtype.name, np.integer)):\n",
    "                val = x[node.attribute_name][key]\n",
    "                if(val < node.threshold):\n",
    "                    node = node.branch['True']\n",
    "                else:\n",
    "                    node = node.branch['False']\n",
    "            else:\n",
    "                val = x[node.attribute_name][key]\n",
    "                node = node.branch[val]\n",
    "                \n",
    "        y_hat.append(node.label)\n",
    "    y_hat = np.asarray(y_hat)\n",
    "    accuracy = calculate_accuracy(y_hat, y)\n",
    "    print(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_hat, y):\n",
    "    count = np.equal(y_hat, y)\n",
    "    value, count = np.unique(count, return_counts = True)\n",
    "    val_count = dict(zip(value, count))\n",
    "        \n",
    "    accuracy = 1 - (val_count[False] / y_hat.shape[0])\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

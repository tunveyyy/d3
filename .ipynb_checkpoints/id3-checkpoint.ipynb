{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    node_count = 0\n",
    "    \n",
    "    def __init__(self, attribute_name, is_continuous, threshold, total_positive, total_negative, is_leaf, label, branch):\n",
    "        self.attribute_name = attribute_name\n",
    "        self.is_continuous = is_continuous\n",
    "        self.threshold = threshold\n",
    "        self.total_positive = total_positive\n",
    "        self.total_negative = total_negative\n",
    "        self.is_leaf = is_leaf\n",
    "        self.label = label\n",
    "        self.branch = branch\n",
    "        Node.node_count += 1\n",
    "        \n",
    "    def get_total_nodes(self):\n",
    "        return self.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_temp(path):\n",
    "    column_names = ['days', 'outlook', 'temperature', 'humidity', 'wind', 'decision']\n",
    "    data = pd.read_csv(path, names = column_names)\n",
    "    data = data.drop(['days'], axis = 1)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(train_data_path, dev_data_path, test_data_path):\n",
    "    column_names = ['age', 'workclass', 'education', 'marital-status', 'occupation', 'race', 'sex', 'hours', 'country', 'income']\n",
    "    train_data = pd.read_csv(train_data_path, names = column_names)\n",
    "    dev_data = pd.read_csv(dev_data_path, names = column_names)\n",
    "    test_data = pd.read_csv(test_data_path, names = column_names)\n",
    "    \n",
    "    return (train_data, dev_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_values(data):\n",
    "    \n",
    "    attributes = data.columns.values\n",
    "    index = np.argwhere(attributes == attributes[-1])\n",
    "    attributes = np.delete(attributes, index)\n",
    "    \n",
    "    labels = np.unique(data.iloc[:, -1])\n",
    "    \n",
    "    positive_label = labels[0]\n",
    "    negative_label = labels[1]\n",
    "    \n",
    "    return attributes, positive_label, negative_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "\n",
    "    def __init__(self, positive_label_val, negative_label_val):\n",
    "        self.positive_label_val = positive_label_val\n",
    "        self.negative_label_val = negative_label_val\n",
    "    \n",
    "    def build_tree(self, data, attributes):\n",
    "        \n",
    "        # Create a node\n",
    "        node = Node(None, False, None, None, None, None, False, None)\n",
    "\n",
    "        # Get positive and negative label\n",
    "        values, count = np.unique(data.iloc[:, -1], return_counts = True)\n",
    "        val_count = dict(zip(values, count))\n",
    "        \n",
    "        positive_label = 0\n",
    "        negative_label = 0\n",
    "        \n",
    "        if(len(val_count) == 2):\n",
    "            positive_label = list(val_count)[0]\n",
    "            negative_label = list(val_count)[1]\n",
    "            node.total_positive = val_count[positive_label]\n",
    "            node.total_negative = val_count[negative_label]\n",
    "        else:\n",
    "            if(self.positive_label_val == list(val_count.keys())[0]):\n",
    "                positive_label = list(val_count)[0]\n",
    "                negative_label = 0 \n",
    "                node.total_positive = val_count[positive_label]\n",
    "                node.total_negative = 0\n",
    "            else:\n",
    "                positive_label = 0\n",
    "                negative_label = list(val_count)[0]\n",
    "                node.total_positive = 0\n",
    "                node.total_negative = val_count[negative_label]\n",
    "\n",
    "        \n",
    "            \n",
    "        if(node.total_negative == 0):\n",
    "            node.is_leaf = True\n",
    "            node.label = positive_label\n",
    "            return node\n",
    "\n",
    "        if(node.total_positive == 0):\n",
    "            node.is_leaf = True\n",
    "            node.label = negative_label\n",
    "            return node\n",
    "\n",
    "        if(len(attributes) == 0):\n",
    "            node.is_leaf = True\n",
    "            if(node.total_positive > node.total_negative):\n",
    "                node.label = positive_label\n",
    "            else:\n",
    "                node.label = negative_label\n",
    "            return node\n",
    "\n",
    "        else:\n",
    "\n",
    "            info_gains = {}\n",
    "            thresholds = {}\n",
    "\n",
    "            for attribute in attributes:\n",
    "                if(np.issubdtype(train_data[attribute].dtype.name, np.integer)):\n",
    "                    thresholds[attribute], info_gains[attribute] = self.calculate_threshold(data[attribute], data.iloc[:, -1])\n",
    "                else:\n",
    "                    info_gains[attribute] = self.information_gain(data[attribute], data.iloc[:, -1])\n",
    "\n",
    "            # Attribute with maximum gain\n",
    "            max_gain_attr = max(info_gains.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "            # If continuous attribute, set threshold value\n",
    "            if(max_gain_attr in list(thresholds.keys())):\n",
    "                node.threshold = thresholds[max_gain_attr]\n",
    "                node.is_continuous = True\n",
    "\n",
    "            node.attribute_name = max_gain_attr\n",
    "            node.branch = {}\n",
    "            \n",
    "            # Check if the best attribute is continuous or categorical\n",
    "            if(node.is_continuous):\n",
    "                for value in [True, False]:\n",
    "                    data[data[max_gain_attr] < node.threshold] = True\n",
    "                    data[data[max_gain_attr] >= node.threshold] = False\n",
    "                    node.branch[value] = None\n",
    "                    subset = data[data[max_gain_attr] == value]\n",
    "                    if(subset.shape[0] == 0):\n",
    "                        node.branch[value] = Node(None, False, None, None, None, None, True, None)\n",
    "                        c, v = np.unique(data.iloc[:,-1], return_counts = True)\n",
    "                        c_v = dict(zip(c, v))\n",
    "                        key = max(c_v.items(), key=operator.itemgetter(1))[0]\n",
    "                        node.branch[value].label = key\n",
    "                    else:\n",
    "                        index = np.argwhere(attributes == max_gain_attr)\n",
    "                        attributes = np.delete(attributes, index)\n",
    "                        node.branch[value] = self.build_tree(subset, attributes)\n",
    "                \n",
    "            else:\n",
    "                # For each unique value from attribute column\n",
    "                for value in np.unique(data[max_gain_attr]):\n",
    "                    node.branch[value] = None\n",
    "                    subset = data[data[max_gain_attr] == value]\n",
    "                    if(subset.shape[0] == 0):\n",
    "                        node.branch[value] = Node(None, False, None, None, None, None, True, None)\n",
    "                        c, v = np.unique(data.iloc[:,-1], return_counts = True)\n",
    "                        c_v = dict(zip(c, v))\n",
    "                        key = max(c_v.items(), key=operator.itemgetter(1))[0]\n",
    "                        node.branch[value].label = key\n",
    "                    else:\n",
    "                        index = np.argwhere(attributes == max_gain_attr)\n",
    "                        attributes = np.delete(attributes, index)\n",
    "                        node.branch[value] = self.build_tree(subset, attributes)\n",
    "\n",
    "        return node\n",
    "    \n",
    "    def calculate_threshold(self, data, label):\n",
    "        data = data.values\n",
    "        label = label.values\n",
    "        indexes = data.argsort()\n",
    "        data = np.flip(data[indexes[::-1]])\n",
    "        label = np.flip(label[indexes[::-1]])\n",
    "        label_df = pd.DataFrame(label)\n",
    "        candidate_threshold = []\n",
    "        info_gains = []\n",
    "\n",
    "        for i in range(data.size - 1):\n",
    "            threshold = data[i] + (data[i + 1] - data[i]) / 2\n",
    "            if threshold not in candidate_threshold:\n",
    "                candidate_threshold.append(threshold)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        for threshold in candidate_threshold:\n",
    "            values = data < threshold\n",
    "            values_df = pd.DataFrame(values)\n",
    "            gain = self.information_gain(values_df, label_df)\n",
    "            info_gains.append(gain)\n",
    "\n",
    "        m = max(info_gains)\n",
    "        max_posn = [i for i, j in enumerate(info_gains) if j == m]\n",
    "        candidate_threshold = np.array(candidate_threshold)\n",
    "        threshold = candidate_threshold[max_posn][0]\n",
    "        \n",
    "        return threshold, m\n",
    "    \n",
    "    def information_gain(self, data, label):\n",
    "        attributes, count = np.unique(data, return_counts = True)\n",
    "        attribute_count = dict(zip(attributes, count))\n",
    "        label = label.values\n",
    "        data = data.values\n",
    "        entropies = []\n",
    "        for attribute in attribute_count:\n",
    "            index = np.where(data == attribute)\n",
    "            op_cls = np.take(label, index)[0]\n",
    "            ops, total = np.unique(op_cls, return_counts = True)\n",
    "            ops_total = dict(zip(ops, total))\n",
    "            entropy = 0\n",
    "            try:\n",
    "                entropy = self.calculate_entropy(ops_total[list(ops_total)[0]], ops_total[list(ops_total)[1]])\n",
    "            except:\n",
    "                entropy = self.calculate_entropy(ops_total[list(ops_total)[0]])\n",
    "            entropy = entropy * (attribute_count[attribute] / len(label))\n",
    "            entropies.append(entropy)\n",
    "        ops, total = np.unique(label, return_counts = True)\n",
    "        ops_total = dict(zip(ops, total))\n",
    "        \n",
    "        entropy = self.calculate_entropy(ops_total[list(ops_total)[0]], ops_total[list(ops_total)[1]])\n",
    "        information = entropy - np.sum(entropies)\n",
    "        return information\n",
    "    \n",
    "    def calculate_entropy(self, positive, negative = 0):\n",
    "        total = positive + negative\n",
    "        if negative == 0:\n",
    "            return - (positive/total) * math.log((positive/total), 2)\n",
    "        else:\n",
    "            return - (positive/total) * math.log((positive/total), 2) - (negative/total) * math.log((negative/total), 2)\n",
    "        \n",
    "    \n",
    "    def score(self, data, node):\n",
    "        labels = data.iloc[:, -1].values\n",
    "        data = data.values\n",
    "        \n",
    "        print(labels)\n",
    "        print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.loc._setitem_with_indexer(indexer, value)\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_array(key, value)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-252-e99fb159898b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Build the tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-251-811d3df4478b>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, data, attributes)\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_gain_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-251-811d3df4478b>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, data, attributes)\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_gain_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-251-811d3df4478b>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, data, attributes)\u001b[0m\n\u001b[1;32m    109\u001b[0m                         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmax_gain_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                         \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-251-811d3df4478b>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(self, data, attributes)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_gain_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_gain_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                     \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_gain_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3131\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3132\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3135\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_setitem_copy\u001b[0;34m(self, stacklevel, t, force)\u001b[0m\n\u001b[1;32m   2671\u001b[0m             \u001b[0;31m# the copy weakref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2673\u001b[0;31m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2674\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_referents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_data_path = 'income-data/income.train.txt'\n",
    "    dev_data_path = 'income-data/income.dev.txt'\n",
    "    test_data_path = 'income-data/income.test.txt'\n",
    "    temp_data_path = 'income-data/data.csv'\n",
    "    \n",
    "    (train_data, dev_data, test_data) = read_data(train_data_path, dev_data_path, test_data_path)\n",
    "    \n",
    "    #train_data = read_temp(temp_data_path)\n",
    "    \n",
    "    (attributes, positive_lab, negative_lab) = get_initial_values(train_data)\n",
    "    \n",
    "    # Create an instance of Decision Tree\n",
    "    dt = DecisionTree(positive_lab, negative_lab)\n",
    "    \n",
    "    # Build the tree\n",
    "    root = dt.build_tree(train_data, attributes)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{22: <__main__.Node object at 0x11e34a978>, 23: <__main__.Node object at 0x11e34acf8>, 24: <__main__.Node object at 0x11e34a780>, 25: <__main__.Node object at 0x11e34a860>, 26: <__main__.Node object at 0x11e34aba8>, 27: <__main__.Node object at 0x11e34ae10>, 28: <__main__.Node object at 0x11e34ad30>, 29: <__main__.Node object at 0x11e34a8d0>, 30: <__main__.Node object at 0x11e34ae48>, 31: <__main__.Node object at 0x11e34ada0>, 32: <__main__.Node object at 0x11cfcaf98>, 33: <__main__.Node object at 0x11e34af28>, 34: <__main__.Node object at 0x11cfcab38>, 35: <__main__.Node object at 0x11cfcaef0>, 36: <__main__.Node object at 0x11cfca4a8>, 37: <__main__.Node object at 0x11cfa9fd0>, 38: <__main__.Node object at 0x11cfa9f28>, 39: <__main__.Node object at 0x11cfcae48>, 40: <__main__.Node object at 0x11cfa90b8>, 41: <__main__.Node object at 0x11cfca9e8>, 42: <__main__.Node object at 0x11cfa9748>, 43: <__main__.Node object at 0x11cfd2f60>, 44: <__main__.Node object at 0x11cfa9908>, 45: <__main__.Node object at 0x11cfd2828>, 46: <__main__.Node object at 0x11cfd2be0>, 47: <__main__.Node object at 0x11cfb8470>, 48: <__main__.Node object at 0x11cfd2f28>, 49: <__main__.Node object at 0x11cfb8f60>, 50: <__main__.Node object at 0x11cfb8eb8>, 51: <__main__.Node object at 0x11cfb8320>, 52: <__main__.Node object at 0x11cfd8898>, 53: <__main__.Node object at 0x11cfb8a58>, 54: <__main__.Node object at 0x11cfd8278>, 55: <__main__.Node object at 0x11cfd8fd0>, 56: <__main__.Node object at 0x11cfd85f8>, 57: <__main__.Node object at 0x11cfd8668>, 58: <__main__.Node object at 0x11cfd8da0>, 59: <__main__.Node object at 0x11cfb5e80>, 60: <__main__.Node object at 0x11cfb5048>, 61: <__main__.Node object at 0x11cfb5d30>, 62: <__main__.Node object at 0x11cfb5a90>, 63: <__main__.Node object at 0x11cfb5898>, 64: <__main__.Node object at 0x11cfb57f0>, 65: <__main__.Node object at 0x11cfb5f28>, 66: <__main__.Node object at 0x11cfb5358>, 67: <__main__.Node object at 0x11cfb5f98>, 68: <__main__.Node object at 0x11cfc34e0>, 69: <__main__.Node object at 0x11cfc3160>, 71: <__main__.Node object at 0x11cfc31d0>, 74: <__main__.Node object at 0x11cfc3048>, 75: <__main__.Node object at 0x11cfc32b0>, 76: <__main__.Node object at 0x11cfc3208>, 78: <__main__.Node object at 0x11cfc34a8>, 83: <__main__.Node object at 0x11cfc30f0>}\n"
     ]
    }
   ],
   "source": [
    "# Get training accuracy\n",
    "train_accuracy = score(train_data, root)\n",
    "#dev_acuracy = score(dev_data, root)\n",
    "#test_accuracy = score(test_data, root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(data, node):\n",
    "    y_hat = []\n",
    "    y = data.iloc[:, -1].values\n",
    "    x = data.drop(data.columns.values[-1], axis = 1)\n",
    "    \n",
    "    for key, value in x.iterrows():\n",
    "        while(node.is_leaf != True):\n",
    "            # If the column is continuous\n",
    "            if(np.issubdtype(x[node.attribute_name].dtype.name, np.integer)):\n",
    "                print(node.branch)\n",
    "                val = x[node.attribute_name][key]\n",
    "                node = node.branch[val]\n",
    "            else:\n",
    "                val = x[node.attribute_name][key]\n",
    "                node = node.branch[val]\n",
    "                \n",
    "            \n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_hat, y):\n",
    "    count = np.equal(y_hat, y)\n",
    "    value, count = np.unique(count, return_counts = True)\n",
    "    val_count = dict(zip(value, count))\n",
    "        \n",
    "    accuracy = 1 - (val_count[False] / y_hat.shape[0])\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

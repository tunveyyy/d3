{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    node_count = 0\n",
    "    \n",
    "    def __init__(self, attribute_name, is_continuous, threshold, total_positive, total_negative, is_leaf, label, branch):\n",
    "        self.attribute_name = attribute_name\n",
    "        self.is_continuous = is_continuous\n",
    "        self.threshold = threshold\n",
    "        self.total_positive = total_positive\n",
    "        self.total_negative = total_negative\n",
    "        self.is_leaf = is_leaf\n",
    "        self.label = label\n",
    "        self.branch = branch\n",
    "        Node.node_count += 1\n",
    "        \n",
    "    def get_total_nodes(self):\n",
    "        return self.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_temp(path):\n",
    "    column_names = ['days', 'outlook', 'temperature', 'humidity', 'wind', 'decision']\n",
    "    data = pd.read_csv(path, names = column_names)\n",
    "    data = data.drop(['days'], axis = 1)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(train_data_path, dev_data_path, test_data_path):\n",
    "    column_names = ['age', 'workclass', 'education', 'marital-status', 'occupation', 'race', 'sex', 'hours', 'country', 'income']\n",
    "    train_data = pd.read_csv(train_data_path, names = column_names)\n",
    "    dev_data = pd.read_csv(dev_data_path, names = column_names)\n",
    "    test_data = pd.read_csv(test_data_path, names = column_names)\n",
    "    \n",
    "    return (train_data, dev_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_values(data):\n",
    "    \n",
    "    # Remove last column from attribute list\n",
    "    attributes = data.columns.values\n",
    "    index = np.argwhere(attributes == attributes[-1])\n",
    "    attributes = np.delete(attributes, index)\n",
    "    \n",
    "    # Get positive and negative labels\n",
    "    labels = np.unique(data.iloc[:, -1])\n",
    "    positive_label = labels[0]\n",
    "    negative_label = labels[1]\n",
    "    \n",
    "    # Get attribute value count\n",
    "    attr_val_cnt = {}\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        attr = np.unique(data[attribute])\n",
    "        attr_cnt = len(attr)\n",
    "        attr_val_cnt[attribute] = attr_cnt\n",
    "        \n",
    "    return attributes, positive_label, negative_label, attr_val_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self, positive_label_val, negative_label_val, attr_val_count):\n",
    "        self.positive_label_val = positive_label_val\n",
    "        self.negative_label_val = negative_label_val\n",
    "        self.attr_val_count = attr_val_count\n",
    "        \n",
    "    def build_tree(self, data, attributes):\n",
    "        \n",
    "        # Create a node\n",
    "        node = Node(None, False, None, None, None, None, False, None)\n",
    "\n",
    "        # Get positive and negative label\n",
    "        values, count = np.unique(data.iloc[:, -1], return_counts = True)\n",
    "        val_count = dict(zip(values, count))\n",
    "        \n",
    "        positive_label = 0\n",
    "        negative_label = 0\n",
    "        \n",
    "        if(len(val_count) == 2):\n",
    "            positive_label = list(val_count)[0]\n",
    "            negative_label = list(val_count)[1]\n",
    "            node.total_positive = val_count[positive_label]\n",
    "            node.total_negative = val_count[negative_label]\n",
    "        else:\n",
    "            if(self.positive_label_val == list(val_count.keys())[0]):\n",
    "                positive_label = list(val_count)[0]\n",
    "                negative_label = 0 \n",
    "                node.total_positive = val_count[positive_label]\n",
    "                node.total_negative = 0\n",
    "            else:\n",
    "                positive_label = 0\n",
    "                negative_label = list(val_count)[0]\n",
    "                node.total_positive = 0\n",
    "                node.total_negative = val_count[negative_label]\n",
    "        \n",
    "        if(node.total_negative == 0):\n",
    "            node.is_leaf = True\n",
    "            node.label = positive_label\n",
    "            return node\n",
    "\n",
    "        if(node.total_positive == 0):\n",
    "            node.is_leaf = True\n",
    "            node.label = negative_label\n",
    "            return node\n",
    "\n",
    "        if(len(attributes) == 0):\n",
    "            node.is_leaf = True\n",
    "            if(node.total_positive > node.total_negative):\n",
    "                node.label = positive_label\n",
    "            else:\n",
    "                node.label = negative_label\n",
    "            return node\n",
    "\n",
    "        else:\n",
    "\n",
    "            info_gains = {}\n",
    "            thresholds = {}\n",
    "\n",
    "            for attribute in attributes:\n",
    "                if(np.issubdtype(train_data[attribute].dtype.name, np.integer)):\n",
    "                    thresholds[attribute], info_gains[attribute] = self.calculate_threshold(data[attribute], data.iloc[:, -1])\n",
    "                else:\n",
    "                    info_gains[attribute] = self.information_gain(data[attribute], data.iloc[:, -1])\n",
    "\n",
    "            # Attribute with maximum gain\n",
    "            max_gain_attr = max(info_gains.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "            # If continuous attribute, set threshold value\n",
    "            if(max_gain_attr in list(thresholds.keys())):\n",
    "                node.threshold = thresholds[max_gain_attr]\n",
    "                node.is_continuous = True\n",
    "\n",
    "            node.attribute_name = max_gain_attr\n",
    "            node.branch = {}\n",
    "            \n",
    "            # Check if the best attribute is continuous or categorical\n",
    "            if(node.is_continuous):\n",
    "                for value in ['True', 'False']:\n",
    "                    if(value == 'True'):\n",
    "                        data[max_gain_attr] = np.where(data[max_gain_attr] < node.threshold, 'True', 'False')\n",
    "                    node.branch[value] = None\n",
    "                    subset = data[data[max_gain_attr] == value]\n",
    "                    if(subset.shape[0] == 0):\n",
    "                        node.branch[value] = Node(None, True, None, None, None, None, True, None)\n",
    "                        c, v = np.unique(data.iloc[:,-1], return_counts = True)\n",
    "                        c_v = dict(zip(c, v))\n",
    "                        key = max(c_v.items(), key=operator.itemgetter(1))[0]\n",
    "                        node.branch[value].label = key\n",
    "                    else:\n",
    "                        index = np.argwhere(attributes == max_gain_attr)\n",
    "                        attributes = np.delete(attributes, index)\n",
    "                        node.branch[value] = self.build_tree(subset, attributes)\n",
    "                \n",
    "            else:\n",
    "                if(len(np.unique(data[max_gain_attr])) == self.attr_val_count[max_gain_attr]):\n",
    "                    \n",
    "                    # For each unique value from attribute column\n",
    "                    for value in np.unique(data[max_gain_attr]):\n",
    "                        node.branch[value] = None\n",
    "                        subset = data[data[max_gain_attr] == value]\n",
    "                        if(subset.shape[0] == 0):\n",
    "                            node.branch[value] = Node(None, False, None, None, None, None, True, None)\n",
    "                            c, v = np.unique(data.iloc[:,-1], return_counts = True)\n",
    "                            c_v = dict(zip(c, v))\n",
    "                            key = max(c_v.items(), key=operator.itemgetter(1))[0]\n",
    "                            node.branch[value].label = key\n",
    "                        else:\n",
    "                            index = np.argwhere(attributes == max_gain_attr)\n",
    "                            attributes = np.delete(attributes, index)\n",
    "                            node.branch[value] = self.build_tree(subset, attributes)\n",
    "                else:\n",
    "                    # Get prominent label for this node\n",
    "                    node.is_leaf = True\n",
    "                    v, c = np.unique(data.iloc[: , -1], return_counts = True)\n",
    "                    v_c = dict(zip(v, c))\n",
    "                    node.label = max(v_c.items(), key=operator.itemgetter(1))[0]\n",
    "                          \n",
    "\n",
    "        return node\n",
    "    \n",
    "    def calculate_threshold(self, data, label):\n",
    "        data = data.values\n",
    "        label = label.values\n",
    "        indexes = data.argsort()\n",
    "        data = np.flip(data[indexes[::-1]])\n",
    "        label = np.flip(label[indexes[::-1]])\n",
    "        label_df = pd.DataFrame(label)\n",
    "        candidate_threshold = []\n",
    "        info_gains = []\n",
    "\n",
    "        for i in range(data.size - 1):\n",
    "            threshold = data[i] + (data[i + 1] - data[i]) / 2\n",
    "            if threshold not in candidate_threshold:\n",
    "                candidate_threshold.append(threshold)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        for threshold in candidate_threshold:\n",
    "            values = data < threshold\n",
    "            values_df = pd.DataFrame(values)\n",
    "            gain = self.information_gain(values_df, label_df)\n",
    "            info_gains.append(gain)\n",
    "\n",
    "        m = max(info_gains)\n",
    "        max_posn = [i for i, j in enumerate(info_gains) if j == m]\n",
    "        candidate_threshold = np.array(candidate_threshold)\n",
    "        threshold = candidate_threshold[max_posn][0]\n",
    "        \n",
    "        return threshold, m\n",
    "    \n",
    "    def information_gain(self, data, label):\n",
    "        attributes, count = np.unique(data, return_counts = True)\n",
    "        attribute_count = dict(zip(attributes, count))\n",
    "        label = label.values\n",
    "        data = data.values\n",
    "        entropies = []\n",
    "        for attribute in attribute_count:\n",
    "            index = np.where(data == attribute)\n",
    "            op_cls = np.take(label, index)[0]\n",
    "            ops, total = np.unique(op_cls, return_counts = True)\n",
    "            ops_total = dict(zip(ops, total))\n",
    "            entropy = 0\n",
    "            try:\n",
    "                entropy = self.calculate_entropy(ops_total[list(ops_total)[0]], ops_total[list(ops_total)[1]])\n",
    "            except:\n",
    "                entropy = self.calculate_entropy(ops_total[list(ops_total)[0]])\n",
    "            entropy = entropy * (attribute_count[attribute] / len(label))\n",
    "            entropies.append(entropy)\n",
    "        ops, total = np.unique(label, return_counts = True)\n",
    "        ops_total = dict(zip(ops, total))\n",
    "        \n",
    "        entropy = self.calculate_entropy(ops_total[list(ops_total)[0]], ops_total[list(ops_total)[1]])\n",
    "        information = entropy - np.sum(entropies)\n",
    "        return information\n",
    "    \n",
    "    def calculate_entropy(self, positive, negative = 0):\n",
    "        total = positive + negative\n",
    "        if negative == 0:\n",
    "            return - (positive/total) * math.log((positive/total), 2)\n",
    "        else:\n",
    "            return - (positive/total) * math.log((positive/total), 2) - (negative/total) * math.log((negative/total), 2)\n",
    "        \n",
    "    \n",
    "    def score(self, data, node):\n",
    "        labels = data.iloc[:, -1].values\n",
    "        data = data.values\n",
    "        \n",
    "        print(labels)\n",
    "        print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 72, 'workclass': 7, 'education': 16, 'marital-status': 7, 'occupation': 14, 'race': 5, 'sex': 2, 'hours': 94, 'country': 41}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_data_path = 'income-data/income.train.txt'\n",
    "    dev_data_path = 'income-data/income.dev.txt'\n",
    "    test_data_path = 'income-data/income.test.txt'\n",
    "    temp_data_path = 'income-data/data.csv'\n",
    "    \n",
    "    (train_data, dev_data, test_data) = read_data(train_data_path, dev_data_path, test_data_path)\n",
    "    \n",
    "    #train_data = read_temp(temp_data_path)\n",
    "    \n",
    "    (attributes, positive_lab, negative_lab, attr_val_cnt) = get_initial_values(train_data)\n",
    "    \n",
    "    # Create an instance of Decision Tree\n",
    "    dt = DecisionTree(positive_lab, negative_lab, attr_val_cnt)\n",
    "    \n",
    "    \n",
    "    # Build the tree\n",
    "    root = dt.build_tree(train_data, attributes)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marital-status {' Divorced': <__main__.Node object at 0x112ddec50>, ' Married-AF-spouse': <__main__.Node object at 0x112e45b00>, ' Married-civ-spouse': <__main__.Node object at 0x112dded30>, ' Married-spouse-absent': <__main__.Node object at 0x112e465f8>, ' Never-married': <__main__.Node object at 0x1130ac780>, ' Separated': <__main__.Node object at 0x112f69978>, ' Widowed': <__main__.Node object at 0x1130acc18>}\n",
      "education {' 10th': <__main__.Node object at 0x112e4d588>, ' 11th': <__main__.Node object at 0x112e46160>, ' 12th': <__main__.Node object at 0x1036a0c18>, ' 1st-4th': <__main__.Node object at 0x1036a39e8>, ' 5th-6th': <__main__.Node object at 0x1036a0588>, ' 7th-8th': <__main__.Node object at 0x1036a35f8>, ' 9th': <__main__.Node object at 0x1036cfda0>, ' Assoc-acdm': <__main__.Node object at 0x112e46a58>, ' Assoc-voc': <__main__.Node object at 0x1036cf048>, ' Bachelors': <__main__.Node object at 0x112f2ea20>, ' Doctorate': <__main__.Node object at 0x112f520f0>, ' HS-grad': <__main__.Node object at 0x112f2e5f8>, ' Masters': <__main__.Node object at 0x1036c6780>, ' Preschool': <__main__.Node object at 0x112e46390>, ' Prof-school': <__main__.Node object at 0x112e46c50>, ' Some-college': <__main__.Node object at 0x112e46f28>}\n",
      "occupation {' Adm-clerical': <__main__.Node object at 0x1036c6048>, ' Craft-repair': <__main__.Node object at 0x112f53978>, ' Exec-managerial': <__main__.Node object at 0x112f531d0>, ' Farming-fishing': <__main__.Node object at 0x112f66be0>, ' Handlers-cleaners': <__main__.Node object at 0x112f53f98>, ' Machine-op-inspct': <__main__.Node object at 0x112f66da0>, ' Other-service': <__main__.Node object at 0x112f53e80>, ' Prof-specialty': <__main__.Node object at 0x11312d7f0>, ' Protective-serv': <__main__.Node object at 0x113147fd0>, ' Sales': <__main__.Node object at 0x113147dd8>, ' Tech-support': <__main__.Node object at 0x113157d30>, ' Transport-moving': <__main__.Node object at 0x11314c470>}\n",
      "country {' Canada': <__main__.Node object at 0x112f66710>, ' China': <__main__.Node object at 0x112f66978>, ' Cuba': <__main__.Node object at 0x112f66588>, ' Dominican-Republic': <__main__.Node object at 0x112f66f98>, ' England': <__main__.Node object at 0x112f66fd0>, ' France': <__main__.Node object at 0x112f66e48>, ' Germany': <__main__.Node object at 0x112f66940>, ' Greece': <__main__.Node object at 0x112f661d0>, ' Hong': <__main__.Node object at 0x112f666d8>, ' India': <__main__.Node object at 0x112f66ef0>, ' Iran': <__main__.Node object at 0x112f66160>, ' Italy': <__main__.Node object at 0x112f66ba8>, ' Japan': <__main__.Node object at 0x112f66550>, ' Mexico': <__main__.Node object at 0x112f66ac8>, ' Philippines': <__main__.Node object at 0x11312b470>, ' Puerto-Rico': <__main__.Node object at 0x11312b780>, ' South': <__main__.Node object at 0x11312b6d8>, ' Taiwan': <__main__.Node object at 0x11312b320>, ' United-States': <__main__.Node object at 0x11312b630>, ' Yugoslavia': <__main__.Node object at 0x11312dfd0>}\n",
      "age {'True': <__main__.Node object at 0x11312b9e8>, 'False': <__main__.Node object at 0x11312b710>}\n",
      "workclass {' Federal-gov': <__main__.Node object at 0x11313cef0>, ' Local-gov': <__main__.Node object at 0x11313cd30>, ' Private': <__main__.Node object at 0x11313cbe0>, ' Self-emp-inc': <__main__.Node object at 0x11313d208>, ' Self-emp-not-inc': <__main__.Node object at 0x11313ca20>, ' State-gov': <__main__.Node object at 0x11313df98>}\n",
      "hours {'True': <__main__.Node object at 0x11313ce80>, 'False': <__main__.Node object at 0x11313c9e8>}\n",
      "sex {' Female': <__main__.Node object at 0x11313df60>, ' Male': <__main__.Node object at 0x11313dd68>}\n",
      "race {' White': <__main__.Node object at 0x113147630>}\n"
     ]
    }
   ],
   "source": [
    "# Get training accuracy\n",
    "traverse(train_data, root)\n",
    "#train_accuracy = score(train_data, root)\n",
    "#dev_acuracy = score(dev_data, root)\n",
    "#test_accuracy = score(test_data, root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(data, node):\n",
    "    root = node\n",
    "    y_hat = []\n",
    "    y = data.iloc[:, -1].values\n",
    "    x = data.drop(data.columns.values[-1], axis = 1)\n",
    "    \n",
    "    for key, value in x.iterrows():\n",
    "        while(node.is_leaf != True):\n",
    "            val = x[node.attribute_name][key]\n",
    "            if(np.issubdtype(x[node.attribute_name].dtype.name, np.integer)):\n",
    "                if(val < node.threshold):\n",
    "                    node = node.branch['True']\n",
    "                else:\n",
    "                    node = node.branch['False']\n",
    "            else:\n",
    "                node = node.branch[val]     \n",
    "        y_hat.append(node.label)\n",
    "        node = root\n",
    "        \n",
    "    y_hat = np.asarray(y_hat)\n",
    "    accuracy = calculate_accuracy(y_hat, y)\n",
    "    print(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_hat, y):\n",
    "    count = np.equal(y_hat, y)\n",
    "    value, count = np.unique(count, return_counts = True)\n",
    "    val_count = dict(zip(value, count))\n",
    "        \n",
    "    accuracy = 1 - (val_count[False] / y_hat.shape[0])\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(data, node):\n",
    "    y = data.iloc[:, -1].values\n",
    "    x = data.drop(data.columns.values[-1], axis = 1)\n",
    "    \n",
    "    for key, value in x.iterrows():\n",
    "        while(node.is_leaf != True):\n",
    "            val = x[node.attribute_name][key]\n",
    "            branch = node.branch\n",
    "            print(node.attribute_name, branch)\n",
    "            if(np.issubdtype(x[node.attribute_name].dtype.name, np.integer)):\n",
    "                if(val < node.threshold):\n",
    "                    node = node.branch['True']\n",
    "                else:\n",
    "                    node = node.branch['False']\n",
    "            else:\n",
    "                node = node.branch[val]     \n",
    "        node = root\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
